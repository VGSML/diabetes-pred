{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open analysis duckdb database\n",
    "import duckdb\n",
    "\n",
    "conn = duckdb.connect('/data/vgribanov/data/a1c1/final_data/analyze_rnn.duckdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 657/657 [06:58<00:00,  1.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create analysis duckdb database (requires trained model and dataset\n",
    "from analysis import load_model, predict, create_analysis_db\n",
    "\n",
    "# Load model and dataset\n",
    "model, ds = load_model(\"/data/vgribanov/a1c1/models/final/rnn.model\")\n",
    "# Results of prediction across all dataset\n",
    "dfResults = predict(model, ds)\n",
    "# Create analysis duckdb database\n",
    "conn = create_analysis_db(\"/data/vgribanov/data/a1c1/final_data\", \"analyze_rnn\", dfResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create individual and save prediction results\n",
    "\n",
    "individual_limit = 10\n",
    "result_json_file = \"/data/vgribanov/data/a1c1/final_data/analyze_rnn_individual.json\"\n",
    "result_yaml_file = \"/data/vgribanov/data/a1c1/final_data/analyze_rnn_individual.yaml\"\n",
    "\n",
    "dfi = conn.query(f\"\"\"\n",
    "    with target_1 as (\n",
    "        select results.idx, results.target, results.logit, data.static_data, data.dynamic_data, data.months\n",
    "        from results\n",
    "                inner join data on results.idx = data.idx\n",
    "        where result and target = 1\n",
    "        order by logit desc\n",
    "        limit {individual_limit}\n",
    "    ), target_0 as (\n",
    "        select results.idx, results.target, results.logit, data.static_data, data.dynamic_data, data.months\n",
    "        from results\n",
    "                inner join data on results.idx = data.idx\n",
    "        where result and target = 0\n",
    "        order by logit desc\n",
    "        limit {individual_limit}\n",
    "    ), target as (\n",
    "        from target_1\n",
    "        union all\n",
    "        from target_0\n",
    "    ), target_static_data as (\n",
    "        with target_static_data as (\n",
    "            select idx, unnest(static_data) as static_data_id\n",
    "            from target\n",
    "        )\n",
    "        select idx, array_agg({{ id: static_data_id, feature: static_data_vocab.type, description: static_data_vocab.value }}) as static_data\n",
    "        from target_static_data\n",
    "                inner join static_data_vocab on target_static_data.static_data_id = static_data_vocab.id\n",
    "        group by all\n",
    "    ), target_dynamic_data as (\n",
    "        with target_dynamic_data_m as (\n",
    "            select idx, unnest(months) as month, unnest(dynamic_data) as dynamic_data_vec\n",
    "            from target\n",
    "        ), target_dynamic_data_unnested as (\n",
    "            select idx, month, unnest(dynamic_data_vec) as dynamic_data_id\n",
    "            from target_dynamic_data_m\n",
    "        ), target_dynamic_data_mu as (\n",
    "            select idx, target_dynamic_data_unnested.month,\n",
    "                array_agg({{ \n",
    "                    id: dynamic_data_id, \n",
    "                    type: dynamic_data_vocab.type, \n",
    "                    code: dynamic_data_vocab.code,\n",
    "                    description: coalesce(\n",
    "                        codes.description, \n",
    "                        dynamic_data_vocab.text_res\n",
    "                    )\n",
    "                }}) as dynamic_data\n",
    "            from target_dynamic_data_unnested\n",
    "                    inner join dynamic_data_vocab on target_dynamic_data_unnested.dynamic_data_id = dynamic_data_vocab.id\n",
    "                    left join codes on dynamic_data_vocab.code = codes.code\n",
    "            group by all\n",
    "       )\n",
    "        select idx, array_agg({{ month: target_dynamic_data_mu.month,  data: dynamic_data }}) as dynamic_data\n",
    "        from target_dynamic_data_mu\n",
    "        group by all\n",
    "    )\n",
    "    select target.idx, target.target, logit, target_static_data.static_data, target_dynamic_data.dynamic_data\n",
    "    from target\n",
    "            inner join target_static_data on target.idx = target_static_data.idx\n",
    "            inner join target_dynamic_data on target.idx = target_dynamic_data.idx\n",
    "    order by logit desc\n",
    "\"\"\").df()\n",
    "\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "json_data = dfi.to_json(orient=\"table\")\n",
    "with open(result_json_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(json_data)\n",
    "\n",
    "\n",
    "def convert_numpy(obj):\n",
    "    if isinstance(obj, np.ndarray):  # numpy array -> list\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, (np.integer, np.floating)):  # numpy int/float -> Python int/float\n",
    "        return obj.item()\n",
    "    elif isinstance(obj, dict):  # Рекурсивно применяем к словарям\n",
    "        return {k: convert_numpy(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):  # Рекурсивно применяем к спискам\n",
    "        return [convert_numpy(v) for v in obj]\n",
    "    return obj  \n",
    "\n",
    "yaml_data = yaml.dump(convert_numpy(json_data), allow_unicode=True, default_flow_style=False, indent=4)\n",
    "with open(result_yaml_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    yaml.dump(yaml_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing most significant procedures and diagnoses data for plotting\n",
    "\n",
    "limit = 10\n",
    "\n",
    "df_procs = conn.query(f\"\"\"\n",
    "WITH res AS (\n",
    "    SELECT idx, target, prediction, logit, result, res,\n",
    "        rank() OVER (PARTITION BY target ORDER BY logit DESC) AS rank\n",
    "    FROM results\n",
    "    WHERE result\n",
    "    ORDER BY rank\n",
    "    LIMIT {limit}\n",
    "), mdynamic AS (\n",
    "    SELECT res.target, unnest(months) AS month, unnest(dynamic_data) as feature_vec\n",
    "    FROM res\n",
    "            INNER JOIN data USING (idx)\n",
    "    ORDER BY rank\n",
    "), gd AS (\n",
    "    select target, month, unnest(feature_vec) as feature\n",
    "    from mdynamic\n",
    "    where month <=12\n",
    ")\n",
    "SELECT \n",
    "    37-month as month, \n",
    "    feature, \n",
    "    dynamic_data_vocab.code,\n",
    "    dynamic_data_vocab.code || ' - ' || COALESCE(codes.description, 'none') AS description,\n",
    "    COUNT(*) as count_all,\n",
    "    COALESCE(count(*) FILTER (WHERE target = 1),0) as count_1,\n",
    "    COALESCE(count(*) FILTER (WHERE target = 0),0) as count_0,\n",
    "    count_1 / count_all as ratio_1,\n",
    "    count_0 / count_all as ratio_0,\n",
    "    count_1 - count_0 as diff,\n",
    "    diff / count_all as ratio_diff\n",
    "FROM gd\n",
    "        INNER JOIN dynamic_data_vocab ON dynamic_data_vocab.id = gd.feature\n",
    "        LEFT JOIN codes ON dynamic_data_vocab.code = codes.code || '_' || codes.type\n",
    "WHERE dynamic_data_vocab.type = 'procedures'\n",
    "GROUP BY ALL\n",
    "--HAVING count_all > 30\n",
    "ORDER BY count_all desc, feature, month\n",
    "\"\"\").df()\n",
    "df_diags = conn.query(f\"\"\"\n",
    "WITH res AS (\n",
    "    SELECT idx, target, prediction, logit, result, res,\n",
    "        rank() OVER (PARTITION BY target ORDER BY logit DESC) AS rank\n",
    "    FROM results\n",
    "    WHERE result\n",
    "    ORDER BY rank\n",
    "    LIMIT {limit}\n",
    "), mdynamic AS (\n",
    "    SELECT res.target, unnest(months) AS month, unnest(dynamic_data) as feature_vec\n",
    "    FROM res\n",
    "            INNER JOIN data USING (idx)\n",
    "    ORDER BY rank\n",
    "), gd AS (\n",
    "    select target, month, unnest(feature_vec) as feature\n",
    "    from mdynamic\n",
    "    where month <=12\n",
    ")\n",
    "SELECT \n",
    "    37-month as month, \n",
    "    feature, \n",
    "    dynamic_data_vocab.code,\n",
    "    dynamic_data_vocab.code || ' - ' || COALESCE(codes.description, 'none') AS description,\n",
    "    COUNT(*) as count_all,\n",
    "    COALESCE(count(*) FILTER (WHERE target = 1),0) as count_1,\n",
    "    COALESCE(count(*) FILTER (WHERE target = 0),0) as count_0,\n",
    "    count_1 / count_all as ratio_1,\n",
    "    count_0 / count_all as ratio_0,\n",
    "    count_1 - count_0 as diff,\n",
    "    diff / count_all as ratio_diff\n",
    "FROM gd\n",
    "        INNER JOIN dynamic_data_vocab ON dynamic_data_vocab.id = gd.feature\n",
    "        LEFT JOIN codes ON dynamic_data_vocab.code = codes.code || '_' || codes.type\n",
    "WHERE dynamic_data_vocab.type = 'diagnoses'\n",
    "GROUP BY ALL\n",
    "--HAVING count_all > 15\n",
    "ORDER BY count_all desc, feature, month\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing data for hitmaps\n",
    "conn.execute(\"\"\"DROP TABLE IF EXISTS procs_results;\"\"\")\n",
    "conn.execute(\"\"\"DROP TABLE IF EXISTS diags_results;\"\"\")\n",
    "conn.execute(\"\"\"CREATE TABLE procs_results AS SELECT * FROM df_procs;\"\"\")\n",
    "conn.execute(\"\"\"CREATE TABLE diags_results AS SELECT * FROM df_diags;\"\"\")\n",
    "\n",
    "def prepare_hitmaps_data(t,target):\n",
    "    return conn.query(f\"\"\"\n",
    "        WITH all_data AS (\n",
    "            SELECT description, feature, sum(count_all) as count_all, sum(count_1) as count_1, sum(count_0) as count_0\n",
    "            FROM {t}_results\n",
    "            GROUP BY ALL \n",
    "            ORDER BY count_all desc\n",
    "        ), p_data AS (\n",
    "            PIVOT {t}_results\n",
    "            ON month\n",
    "            USING SUM({target})\n",
    "            GROUP BY description\n",
    "        )\n",
    "        SELECT p_data.*\n",
    "        FROM p_data\n",
    "            INNER JOIN all_data USING (description)\n",
    "        ORDER BY all_data.count_all desc\n",
    "        \"\"\").df()\n",
    "\n",
    "df_procs_1 = prepare_hitmaps_data(\"procs\", \"count_1\")\n",
    "df_procs_0 = prepare_hitmaps_data(\"procs\", \"count_0\")\n",
    "df_procs_diff = prepare_hitmaps_data(\"procs\", \"diff\")\n",
    "df_procs_diff_ratio = prepare_hitmaps_data(\"procs\", \"ratio_diff\")\n",
    "\n",
    "df_diags_1 = prepare_hitmaps_data(\"diags\", \"count_1\")\n",
    "df_diags_0 = prepare_hitmaps_data(\"diags\", \"count_0\")\n",
    "df_diags_diff = prepare_hitmaps_data(\"diags\", \"diff\")\n",
    "df_diags_diff_ratio = prepare_hitmaps_data(\"diags\", \"ratio_diff\")\n",
    "\n",
    "(proc_min, proc_max, proc_1_max, proc_0_max, proc_min_diff, proc_max_diff, proc_min_dr, proc_max_dr) = conn.query(\"\"\"\n",
    "        WITH all_data AS (\n",
    "            SELECT description, month, sum(count_all) as count_all, sum(count_1) as count_1, sum(count_0) as count_0, sum(diff) as diff, sum(ratio_diff) as ratio_diff\n",
    "            FROM procs_results\n",
    "            GROUP BY ALL\n",
    "        )\n",
    "        SELECT min(count_all), max(count_all), \n",
    "            max(count_1) AS m_count_1, max(count_0) AS m_count_0, min(diff) AS min_diff, max(diff) AS max_diff, min(ratio_diff) AS min_ratio, max(ratio_diff) AS max_ratio\n",
    "        FROM all_data\n",
    "\"\"\").df().values[0]\n",
    "\n",
    "(diag_min, diag_max, diag_1_max, diag_0_max, diag_min_diff, diag_max_diff, diag_min_dr, diag_max_dr) = conn.query(\"\"\"\n",
    "        WITH all_data AS (\n",
    "            SELECT description, month, sum(count_all) as count_all, sum(count_1) as count_1, sum(count_0) as count_0, sum(diff) as diff, sum(ratio_diff) as ratio_diff\n",
    "            FROM diags_results\n",
    "            GROUP BY ALL\n",
    "        )\n",
    "        SELECT min(count_all), max(count_all), \n",
    "            max(count_1) AS m_count_1, max(count_0) AS m_count_0, min(diff) AS min_diff, max(diff) AS max_diff, min(ratio_diff) AS min_ratio, max(ratio_diff) AS max_ratio\n",
    "        FROM all_data\n",
    "\"\"\").df().values[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create diagnoses and procedures heatmaps charts\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def print_heatmaps(name, df_diff, df_0, df_1, max0, max1, min_diff, max_diff):\n",
    "    i = 0\n",
    "    diff = df_diff.set_index(\"description\")\n",
    "    df0 = df_0.set_index(\"description\")\n",
    "    df1 = df_1.set_index(\"description\")\n",
    "    for i in range(0, len(df_diff), 20):\n",
    "        fig, axes = plt.subplots(3, figsize=(18, 18))\n",
    "        axes = axes.flatten()\n",
    "        sns.heatmap(df0[i:i+20],annot=False,cmap=\"YlGnBu\",ax=axes[0],cbar=True, vmin=0, vmax=max0)\n",
    "        axes[0].set_title(f\"{name} from {i} to {i+20} for A1 less or equal than 7\")\n",
    "        axes[0].set_ylabel(\"Feature\")\n",
    "        axes[0].set_xlabel(\"Month\")\n",
    "        sns.heatmap(df1[i:i+20],annot=False,cmap=\"YlGnBu\",ax=axes[1],cbar=True, vmin=0, vmax=max1)\n",
    "        axes[1].set_title(f\"{name} {i} to {i+20}  for A1 greater than 7\")\n",
    "        axes[1].set_ylabel(\"Feature\")\n",
    "        axes[1].set_xlabel(\"Month\")\n",
    "        sns.heatmap(diff[i:i+20],annot=False,cmap=\"RdBu\", center=0,ax=axes[2],cbar=True, vmin=min_diff, vmax=max_diff)\n",
    "        axes[2].set_title(f\"{name} {i} to {i+20} difference\")\n",
    "        axes[2].set_ylabel(\"Feature\")\n",
    "        axes[2].set_xlabel(\"Month\")\n",
    "        plt.show()\n",
    "\n",
    "print_heatmaps(\"procedures\", df_procs_diff, df_procs_0, df_procs_1, proc_0_max, proc_1_max, proc_min_diff, proc_max_diff)\n",
    "print_heatmaps(\"diagonses\", df_diags_diff, df_diags_0, df_diags_1, diag_0_max, diag_1_max, diag_min_diff, diag_max_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing labs data for plotting\n",
    "limit = 10\n",
    "df_group_labs = conn.query(f\"\"\"\n",
    "WITH res AS (\n",
    "    SELECT idx, target, prediction, logit, result, res,\n",
    "        rank() OVER (PARTITION BY target ORDER BY logit DESC) AS rank\n",
    "    FROM results\n",
    "    WHERE result\n",
    "    ORDER BY rank\n",
    "    LIMIT {limit}\n",
    "), mdynamic AS (\n",
    "    SELECT res.target, unnest(months) AS month, unnest(dynamic_data) as feature_vec\n",
    "    FROM res\n",
    "            INNER JOIN data USING (idx)\n",
    "    ORDER BY rank\n",
    "), gd AS (\n",
    "    select target, month, unnest(feature_vec) as feature\n",
    "    from mdynamic\n",
    "), pre_data AS (\n",
    "    SELECT \n",
    "        dynamic_data_vocab.code,\n",
    "        COUNT(*) as count\n",
    "    FROM gd\n",
    "            INNER JOIN dynamic_data_vocab ON dynamic_data_vocab.id = gd.feature\n",
    "            LEFT JOIN codes ON dynamic_data_vocab.code = codes.code || '_' || codes.type\n",
    "    WHERE dynamic_data_vocab.type = 'labs'\n",
    "    GROUP BY ALL\n",
    ")\n",
    "SELECT *\n",
    "FROM pre_data\n",
    "ORDER BY count desc\n",
    "\"\"\").df()\n",
    "\n",
    "df_labs = conn.query(f\"\"\"\n",
    "WITH res AS (\n",
    "    SELECT idx, target, prediction, logit, result, res,\n",
    "        rank() OVER (PARTITION BY target ORDER BY logit DESC) AS rank\n",
    "    FROM results\n",
    "    WHERE result\n",
    "    ORDER BY rank\n",
    "    LIMIT {limit}\n",
    "), mdynamic AS (\n",
    "    SELECT res.target, unnest(months) AS month, unnest(dynamic_data) as feature_vec\n",
    "    FROM res\n",
    "            INNER JOIN data USING (idx)\n",
    "    ORDER BY rank\n",
    "), gd AS (\n",
    "    select target, month, unnest(feature_vec) as feature\n",
    "    from mdynamic\n",
    "), pre_agg AS (\n",
    "    SELECT target, month, feature, count(*) as count\n",
    "    FROM gd\n",
    "    GROUP BY ALL\n",
    "), groupped AS (\n",
    "    SELECT code, unnest(array[0,1]) as target\n",
    "    FROM df_group_labs\n",
    "), pre_data AS (\n",
    "    SELECT \n",
    "        groupped.target, \n",
    "        groupped.code,\n",
    "        dynamic_data_vocab.code || ' ' || dynamic_data_vocab.lower_bound || ' - ' || dynamic_data_vocab.upper_bound AS description,\n",
    "        COALESCE(37-month, 1) as month, \n",
    "        COALESCE(SUM(pre_agg.count),0) as count\n",
    "    FROM groupped\n",
    "            INNER JOIN dynamic_data_vocab ON dynamic_data_vocab.code = groupped.code\n",
    "            LEFT JOIN pre_agg ON dynamic_data_vocab.id = pre_agg.feature and groupped.target = pre_agg.target\n",
    "    WHERE dynamic_data_vocab.type = 'labs'\n",
    "    GROUP BY ALL\n",
    "), dd AS (\n",
    "    SELECT target, months.month, code, description, SUM(coalesce(count, 0)) OVER (PARTITION BY target, code) AS rate, coalesce(count, 0) as count\n",
    "    FROM (select unnest(range(1, 36))::integer as month) as months\n",
    "            left join pre_data on months.month = pre_data.month\n",
    "        \n",
    "    ORDER BY rate desc, code, months.month\n",
    ")\n",
    "FROM dd\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot labs data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "for idx, row in df_group_labs.iterrows():\n",
    "    lab_1 = df_labs[(df_labs[\"target\"] == 1)&(df_labs['code']==row['code'])].pivot_table(index=\"description\", columns=\"month\", values=\"count\", aggfunc=\"sum\", fill_value=0)\n",
    "    lab_0 = df_labs[(df_labs[\"target\"] == 0)&(df_labs['code']==row['code'])].pivot_table(index=\"description\", columns=\"month\", values=\"count\", aggfunc=\"sum\", fill_value=0)\n",
    "    lab_diff = lab_1 - lab_0\n",
    "    fig, axes = plt.subplots(3, figsize=(18, 18))\n",
    "    axes = axes.flatten()\n",
    "    sns.heatmap(lab_0,annot=False,cmap=\"YlGnBu\",ax=axes[0],cbar=True)\n",
    "    axes[0].set_title(f\"labs {row['code']} rank {row['count']} for A1 less or equal than 7\")\n",
    "    axes[0].set_ylabel(\"Feature\")\n",
    "    axes[0].set_xlabel(\"Month\")\n",
    "    sns.heatmap(lab_1,annot=False,cmap=\"YlGnBu\",ax=axes[1],cbar=True)\n",
    "    axes[1].set_title(f\"labs {row['code']} rank {row['count']} for A1 greater than 7\")\n",
    "    axes[1].set_ylabel(\"Feature\")\n",
    "    axes[1].set_xlabel(\"Month\")\n",
    "    sns.heatmap(lab_diff,annot=False,cmap=\"RdBu\", center=0,ax=axes[2],cbar=True)\n",
    "    axes[2].set_title(f\"labs {row['code']} rank {row['count']} differences between A1C1 greater and less\")\n",
    "    axes[2].set_ylabel(\"Feature\")\n",
    "    axes[2].set_xlabel(\"Month\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot static features chart\n",
    "limit = 1000\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df_static = conn.query(f\"\"\"\n",
    "WITH res AS (\n",
    "    SELECT idx, target, prediction, logit, result, res,\n",
    "        rank() OVER (PARTITION BY target ORDER BY logit DESC) AS rank\n",
    "    FROM results\n",
    "    WHERE result\n",
    "    ORDER BY rank\n",
    "    LIMIT {limit}\n",
    "), static AS (\n",
    "    SELECT res.target, unnest(static_data) as feature\n",
    "    FROM res\n",
    "            INNER JOIN data USING (idx)\n",
    "    ORDER BY rank\n",
    ")\n",
    "SELECT target, feature, static_data_vocab.type, static_data_vocab.value, COUNT(*) as count\n",
    "FROM static\n",
    "        INNER JOIN static_data_vocab ON static_data_vocab.id = static.feature\n",
    "GROUP BY ALL\n",
    "ORDER BY static_data_vocab.type, static_data_vocab.value\n",
    "\"\"\").df()\n",
    "\n",
    "unique_labels = df_static.sort_values(by=[\"type\", \"value\"])[\"type\"] + \" \" + df_static.sort_values(by=[\"type\", \"value\"])[\"value\"]\n",
    "unique_labels = unique_labels.unique()\n",
    "counts_target_0 = [df_static[(df_static[\"target\"] == 0) & (df_static[\"type\"] + \" \" + df_static[\"value\"] == label)][\"count\"].values[0] if not df_static[(df_static[\"target\"] == 0) & (df_static[\"type\"] + \" \" + df_static[\"value\"] == label)].empty else 0 for label in unique_labels]\n",
    "counts_target_1 = [df_static[(df_static[\"target\"] == 1) & (df_static[\"type\"] + \" \" + df_static[\"value\"] == label)][\"count\"].values[0] if not df_static[(df_static[\"target\"] == 1) & (df_static[\"type\"] + \" \" + df_static[\"value\"] == label)].empty else 0 for label in unique_labels]\n",
    "\n",
    "y_positions = np.arange(len(unique_labels))\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.barh(y_positions - 0.2, counts_target_0, height=0.4, label=\"A1 less or equal than 7\", color=\"skyblue\", alpha=0.8)\n",
    "plt.barh(y_positions + 0.2, counts_target_1, height=0.4, label=\"A1 greater than 7\", color=\"salmon\", alpha=0.8)\n",
    "plt.yticks(y_positions, unique_labels, rotation=0)\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Type and Value\")\n",
    "plt.title(\"Static Features\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Diabetes Prediction)",
   "language": "python",
   "name": "diabt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
